services:
  
  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.1 
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    restart: unless-stopped
    networks:
      - taxi_network

  kafka:
    image: confluentinc/cp-kafka:6.1.1
    hostname: kafka
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "29092:29092"
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: 'zookeeper:2181'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
      KAFKA_NUM_PARTITIONS: 20  # Increased for better parallelism
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_MESSAGE_MAX_BYTES: 10485760  
      # Performance optimizations for high throughput
      KAFKA_SOCKET_SEND_BUFFER_BYTES: 102400
      KAFKA_SOCKET_RECEIVE_BUFFER_BYTES: 102400
      KAFKA_SOCKET_REQUEST_MAX_BYTES: 104857600
      KAFKA_LOG_RETENTION_HOURS: 24  # Reduce retention for large datasets
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB segments
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: 'snappy'  # Enable compression
      KAFKA_BATCH_SIZE: 65536  # 64KB batch size
      KAFKA_LINGER_MS: 10  # Batch messages for better throughput
    restart: unless-stopped
    networks:
      - taxi_network
    deploy:
      resources:
        limits:
          memory: 4G  # Increased memory for better performance
          cpus: "2.0"

  python-producer:
    build:
      context: ./taxi_locations/producer
      dockerfile: Dockerfile
    volumes:
      - ./taxi_locations:/app
    depends_on:
      - zookeeper
      - kafka
    environment:
      KAFKA_BROKER: kafka:29092
    restart: unless-stopped
    networks:
      - taxi_network
    deploy:
      resources:
        limits:
          memory: 4G  # Increased for parallel processing
          cpus: "2.0"  # More CPU for parallel file processing

  redis:
    image: redis:latest
    container_name: redis
    ports:
      - "6379:6379"
    restart: unless-stopped
    networks:
      - taxi_network
    # Redis optimization for high-throughput scenarios
    command: redis-server --appendonly yes --appendfsync everysec --maxmemory 2gb --maxmemory-policy allkeys-lru --tcp-keepalive 60 --timeout 300
    deploy:
      resources:
        limits:
          memory: 2G  # Dedicated memory for Redis
          cpus: "1.0"

  dash-app:
    build:
      context: ./dash-app
      dockerfile: Dockerfile
    container_name: dash-app
    ports:
      - "8050:8050"
    depends_on:
      - redis
    networks:
      - taxi_network
    volumes:
      - ./dash-app:/app
    deploy:
      resources:
        limits:
          memory: 1G  # Increased for better performance
          cpus: "1.0"  # More CPU allocation
  
  flink-jobmanager:
    image: flink:1.18.1-scala_2.12-java17
    container_name: flink-jobmanager
    ports:
      - "8081:8081"
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager        

    command: jobmanager
    restart: unless-stopped
    networks:
      - taxi_network
    deploy:
      resources:
        limits:
          memory: 20G

  
  flink-taskmanager:
    image: flink:1.18.1-scala_2.12-java17
    depends_on:
      - flink-jobmanager
    command: taskmanager
    environment:
      - |
        FLINK_PROPERTIES=
        jobmanager.rpc.address: flink-jobmanager
        taskmanager.numberOfTaskSlots: 20  # Increased for better parallelism
        taskmanager.memory.process.size: 4gb  # More memory for processing
        taskmanager.memory.managed.fraction: 0.4
    restart: unless-stopped
    networks:
      - taxi_network
    deploy:
      resources:
        limits:
          memory: 4G  # Increased memory allocation
          cpus: "2.0"  # More CPU power


networks:
  taxi_network:
    driver: bridge